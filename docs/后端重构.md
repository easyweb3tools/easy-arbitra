# Easy Arbitra 后端重构建议（数据采集架构）

更新时间：2026-02-24  
视角：后端架构师（面向运营数据抓取）

## 1. 结论

当前后端数据采集架构**能支撑 Hackathon 演示**，但**不满足运营化阶段**对“数据完整性、时效性、可回放、可解释”的要求。  
核心结论：

1. 采集链路缺少游标/水位，存在漏数风险。
2. offchain 事件链路未真正落库，直接削弱 Layer3 与异常能力。
3. 聚合与评分以全表扫描为主，随着钱包规模增长会拖垮时效。
4. API 查询大量实时 CTE 计算，运营页面在数据量上升后会退化。

## 2. 审查范围

本次审查覆盖：

1. 采集调度：`backend/cmd/server/main.go`、`backend/internal/worker/*`
2. 数据源适配：`backend/internal/client/*`
3. 入库与聚合：`backend/internal/repository/*`、`backend/migrations/*`
4. 运营消费链路：`/ops/highlights`、`/wallets/potential`、`watchlist/feed`

## 3. 运营侧数据抓取目标（建议明确为 SLO）

建议先把运营需求转成可验收指标：

1. 时效性：核心榜单数据延迟 <= 5 分钟（P95）。
2. 完整性：交易采集漏数率 < 0.1%，支持按时间窗回放重跑。
3. 一致性：同一钱包同一时间窗指标可重复计算、可追溯来源。
4. 可用性：采集任务失败可重试，失败记录可定位。
5. 可扩展性：钱包数/交易量增长 10 倍时，作业窗口可控。

## 4. 主要问题（按严重度）

## P0（必须先改）

1. **offchain 事件链路未落库，信息优势分析基础缺失**  
   - 证据：`OffchainClient` 返回空数组（`backend/internal/client/offchain_client.go:21-28`），`offchain_syncer` 仅调用 fetch，未写库（`backend/internal/worker/offchain_syncer.go:20-23`）。  
   - 影响：`info_edge` 依赖 `offchain_event`（`backend/internal/repository/repository.go:847-873`），但当前几乎无样本，导致大量 `insufficient_data`。

2. **Trade 增量采集无水位，存在漏数风险**  
   - 证据：`FetchTrades` 仅 `limit` 拉取（`backend/internal/client/data_api_client.go:47-53`），`trade_syncer` 轮询仅消费这批数据（`backend/internal/worker/trade_syncer.go:39-49`）。  
   - 影响：高峰期若 5 分钟内交易数 > `max_trades_per_sync`（当前默认 200），历史数据会被滑过。

3. **幂等键设计过弱，可能错误覆盖多笔成交**  
   - 证据：`uniq_key = tx_hash + timestamp`（`backend/internal/worker/trade_ingest.go:58-70`）。  
   - 影响：同一 tx 同秒多 fill 时有冲突风险，可能导致数据丢失或覆盖。

4. **调度缺少作业状态与分布式互斥机制**  
   - 证据：`manager` 仅内存 ticker + goroutine（`backend/internal/worker/manager.go:29-63`），无任务状态表/锁。  
   - 影响：多实例部署会重复抓取、重复计算，且故障恢复不可追踪。

## P1（运营阶段高优先）

1. **Market 采集覆盖不足，元数据质量不稳定**  
   - 证据：`FetchMarkets` 仅按 limit 拉取（`backend/internal/client/gamma_client.go:39-45`），`max_markets_per_sync` 默认 100（`backend/config/config.yaml:59`）；缺失市场通过 `EnsureByConditionID` 生成占位标题（`backend/internal/repository/repository.go:777-794`）。  
   - 影响：市场页出现大量 `market-xxx` + `vol 0` 占位记录，不利于运营内容消费。

2. **Feature/Score/Anomaly 作业全量扫描，规模化不可持续**  
   - 证据：`BuildDaily` 每次从 `trade_fill` 全量聚合（`backend/internal/repository/feature_repository.go:15-75`）；  
     `score_calculator` 每轮遍历全部 wallet（`backend/internal/worker/score_calculator.go:21-31`）；  
     `anomaly scan` 逐钱包聚合（`backend/internal/service/anomaly_service.go:75-143`）。  
   - 影响：钱包数增大后作业周期拉长，榜单刷新会滞后。

3. **运营接口实时重算成本高**  
   - 证据：`potential/ops/highlights` 依赖多层 CTE 扫描 `trade_fill`（`backend/internal/repository/repository.go:315-699`）。  
   - 影响：请求时延随数据量上升而退化，影响首页与运营位稳定性。

4. **“24h 新潜力钱包”口径易受入库时机影响**  
   - 证据：按 `wallet.first_seen_at` 统计（`backend/internal/repository/repository.go:453-503`），而 `first_seen_at` 来源于首次写库时间（`backend/internal/repository/repository.go:707`）。  
   - 影响：回填或延迟写入会扭曲“新增”指标。

## P2（质量与体验）

1. **策略分类规则较硬编码，标签同质化**  
   - 证据：`classification_service` 以固定阈值打分（`backend/internal/service/classification_service.go:33-84`）。  
   - 影响：运营侧“优质钱包分层”区分度不足，影响用户信任和转化。

2. **API 与 Worker 同进程耦合**  
   - 证据：HTTP 服务与 worker 在 `main.go` 同时启动（`backend/cmd/server/main.go:112-134`）。  
   - 影响：采集高峰可能挤占 API 资源，影响前台稳定性。

## 5. 目标架构（To-Be）

建议从“定时拉取 + 在线重算”重构为“增量采集 + 分层计算 + 服务化输出”：

1. **Source Layer（采集层）**  
   - Data API/Gamma/Offchain 适配器，统一分页、重试、限流。
2. **Landing Layer（落地层）**  
   - 原始事件表（raw）+ 强幂等键 + ingest 游标。
3. **Core Layer（事实层）**  
   - 标准化事实表（trade_fill、market、offchain_event）与维表。
4. **Mart Layer（运营层）**  
   - 钱包 5m/1h/24h 聚合表，供首页/榜单/watchlist 直接读。
5. **Serving Layer（API 层）**  
   - API 只做轻量拼装，不在请求时做大扫描。

## 6. 重构路线（建议 4 个阶段）

## 阶段 A（1 周）：先补“正确性与可观测”

1. 新增表：
   - `ingest_cursor(source, stream, cursor_value, updated_at)`
   - `ingest_run(id, job_name, started_at, ended_at, status, stats_json, error_text)`
   - `ingest_dead_letter(id, source, payload, error, retry_count, created_at)`
2. 每个 syncer 写 run 记录、成功/失败指标、处理条数。
3. 引入作业互斥：Postgres advisory lock（按 job_name）。

## 阶段 B（1-2 周）：重做采集链路

1. **Trade 增量**  
   - 优先使用“时间/ID 游标”拉取；若上游限制，采用“滑动窗口重拉 + 幂等去重”。  
   - 扩展幂等键（示例：`tx_hash + token_id + maker + taker + side + price + size + timestamp`）。
2. **Market 全量分页**  
   - 支持分页遍历与增量更新，不再只抓首批 limit。
3. **Offchain 真实接入并落库**  
   - 同步事件必须写入 `offchain_event`，并做 source + event_time 去重。
4. **回放能力**  
   - 支持按时间窗重跑 Trade/Market/Offchain。

## 阶段 C（1 周）：把计算从“全量”改为“增量”

1. 新增聚合表（示例）：
   - `wallet_trade_agg_5m`
   - `wallet_trade_agg_1h`
   - `wallet_trade_agg_24h`
2. Feature/Score/Anomaly 改为“仅处理变更钱包集合”：
   - 由采集阶段产出 `changed_wallet_queue(wallet_id, reason, ts)`。
3. `/ops/highlights`、`/wallets/potential` 改读 mart 表，降低请求时重算开销。

## 阶段 D（1 周）：解耦与扩展

1. 将 worker 独立为单独进程（`cmd/worker`），API 进程只服务请求。
2. 增加采集限流策略（全局 token bucket + source 级并发阈值）。
3. 为关键任务增加优先级和熔断策略（先保 Trade，再保 AI）。

## 7. 关键数据模型重构建议

## 7.1 采集状态模型

```sql
CREATE TABLE ingest_cursor (
  source TEXT NOT NULL,
  stream TEXT NOT NULL,
  cursor_value TEXT NOT NULL,
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  PRIMARY KEY (source, stream)
);
```

## 7.2 作业运行模型

```sql
CREATE TABLE ingest_run (
  id BIGSERIAL PRIMARY KEY,
  job_name TEXT NOT NULL,
  started_at TIMESTAMPTZ NOT NULL,
  ended_at TIMESTAMPTZ,
  status TEXT NOT NULL,
  stats_json JSONB NOT NULL DEFAULT '{}'::jsonb,
  error_text TEXT
);
```

## 7.3 变更驱动计算队列

```sql
CREATE TABLE changed_wallet_queue (
  id BIGSERIAL PRIMARY KEY,
  wallet_id BIGINT NOT NULL,
  reason TEXT NOT NULL,
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  processed_at TIMESTAMPTZ
);
CREATE INDEX idx_changed_wallet_queue_unprocessed
  ON changed_wallet_queue(processed_at, created_at);
```

## 8. API 与运营指标的配套改造

1. `ops/highlights` 改为读取 `wallet_trade_agg_24h + latest_score + latest_ai` 物化视图。  
2. `new_potential_wallets_24h` 改口径为“过去 24h 首次达到潜力阈值”，避免 first_seen 偏差。  
3. Watchlist feed 增加标准事件：
   - `ai_report`
   - `pnl_jump`
   - `risk_level_change`
   - `strategy_change`
4. 每个事件附 `before/after` 与 `reason_code`，便于运营复盘与文案生成。

## 9. 验收标准（重构完成后）

1. Trade 采集支持断点续传，重启后不漏不重。  
2. Offchain 事件样本可持续增长，Layer3 `samples` 不再长期为 0。  
3. 首页/榜单查询 P95 明显下降（目标 < 300ms，本地除外）。  
4. Feature/Score/Anomaly 作业从全量改为增量，作业时长与钱包总量弱相关。  
5. 运营指标（新增潜力、Top24h）在回放后可复现一致。

## 10. 最小落地顺序（建议）

1. 先做阶段 A + B（保证数据正确）。  
2. 再做阶段 C（保证运营时效）。  
3. 最后做阶段 D（保证扩展能力）。  

如果只允许做一件事，优先修复：**Trade 游标化 + Offchain 落库**。  
这是影响运营数据可信度最大的两项。

